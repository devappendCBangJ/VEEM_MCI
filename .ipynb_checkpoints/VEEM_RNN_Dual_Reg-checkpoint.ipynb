{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b03efac7",
   "metadata": {},
   "source": [
    "## 0. 학습 세팅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb85cfe",
   "metadata": {},
   "source": [
    "### 1) 메모리 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1858881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eeaffc",
   "metadata": {},
   "source": [
    "### 2) 수정된 코드 자동 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5ef3621",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import foolbox as fb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bdaec7",
   "metadata": {},
   "source": [
    "## 1. Load library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "891f174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 호출\n",
    "import os\n",
    "import time\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import argparse\n",
    "import easydict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchmetrics.functional.classification import accuracy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from src.engines import train, evaluate, epoch_time\n",
    "from src.utils import load_checkpoint, save_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9b3a52",
   "metadata": {},
   "source": [
    "## 2. Variable Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f39b1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(args.output_size)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Jupyter 외 환경\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"--title\", type=str, default=\"baseline\")\n",
    "# parser.add_argument(\"--device\", type=str, default=\"cuda\")\n",
    "# parser.add_argument(\"--root\", type=str, default=\"data\")\n",
    "# parser.add_argument(\"--batch_size\", type=int, default=64)\n",
    "# parser.add_argument(\"--num_workers\", type=int, default=2)\n",
    "# parser.add_argument(\"--epochs\", type=int, default=100)\n",
    "# parser.add_argument(\"--lr\", type=float, default=0.001)\n",
    "# parser.add_argument(\"--logs\", type=str, default='logs')\n",
    "# parser.add_argument(\"--checkpoints\", type=str, default='checkpoints')\n",
    "# parser.add_argument(\"--resume\", type=bool, default=False)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# Jupyter 환경\n",
    "args = easydict.EasyDict({\n",
    "        \"title\" : \"VEEM_RNN_Reg\",\n",
    "        \"learn_type\" : \"regression\",\n",
    "        \"device\" : \"cuda\",\n",
    "        \"batch_size\" : 32, # !!!\n",
    "        \"num_workers\" : 2,\n",
    "        \"epochs\" : 50, # !!!### 2) 모델 + 옵티마이저 + 손실함수 + 스케쥴러 + 메트릭 함수 정의\n",
    "        \"lr\" : 0.01, # !!!\n",
    "        \"logs\" : \"logs\",\n",
    "        \"checkpoints\" : \"checkpoints\",\n",
    "        \"resume\" : False,\n",
    "        \"test_ratio\" : 0.25,\n",
    "        \"input_size\" : 11,\n",
    "        \"hidden_size\" : 2,\n",
    "        \"num_layers\" : 1,\n",
    "        \"output_size\" : 5,\n",
    "        \"regression_output_size\" : 5,\n",
    "        \"classification_output_size\" : 2,\n",
    "        \"regression_lr\" : 0.01,\n",
    "        \"classification_lr\" : 3e-4,\n",
    "        \"regression_epochs\" : 500,\n",
    "        \"classification_epochs\" : 500\n",
    "    })\n",
    "\n",
    "if(args.learn_type == \"regression\"):\n",
    "    args.output_size = args.regression_output_size\n",
    "    args.lr = args.regression_lr\n",
    "    args.epochs = args.regression_epochs\n",
    "else:\n",
    "    args.output_size = args.classification_output_size\n",
    "    args.lr = args.classification_lr\n",
    "    args.epochs = args.classification_epochs\n",
    "\n",
    "\"\"\"\n",
    "print(args.output_size)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ccbfd5",
   "metadata": {},
   "source": [
    "## 3. Model Define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00db39bf",
   "metadata": {},
   "source": [
    "### 1) 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b61b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(RNN, self).__init__() # 상속한 nn.Module에서 RNN에 해당하는 init 실행\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x): # x : [batch_size, sequence_length, input_size]\n",
    "        \"\"\"\n",
    "        print(\"x.shape : \", x.shape)\n",
    "        print(\"x : \", x)\n",
    "        \"\"\"\n",
    "        # hidden state + cell state 초기화 (Bi-directional LSTM : 아래의 hidden and cell states의 첫번째 차원은 2*self.num_layers)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(args.device) # h0 : [num_layers, batch_size, hidden_size]\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(args.device) # c0 : [num_layers, batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        print(\"h0.shape : \", h0.shape)\n",
    "        print(\"c0.shape : \", c0.shape)\n",
    "        \n",
    "        print(\"h0 : \", h0)\n",
    "        print(\"c0 : \", c0)\n",
    "        \"\"\"\n",
    "\n",
    "        # LSTM 순전파\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0)) # out : [batch_size, sequence_length, hidden_size]\n",
    "        \"\"\"\n",
    "        print(\"out.shape : \", out.shape)\n",
    "        print(\"out : \", out)\n",
    "        \"\"\"\n",
    "        \n",
    "        # 마지막 time step(sequence length)의 hidden state 반환\n",
    "        \"\"\"\n",
    "        print(\"out[:, -1, :] : \", out[:, -1, :])\n",
    "        \"\"\"\n",
    "        out = self.fc(out[:, -1, :]) # out : [batch_size, hidden_size] -> out : [batch_size, output_size]\n",
    "        \"\"\"\n",
    "        print(\"out.shape : \", out.shape)\n",
    "        print(\"out : \", out)\n",
    "        \"\"\"\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551357fe",
   "metadata": {},
   "source": [
    "### 2) 모델 + 옵티마이저 + 손실함수 + 스케쥴러 + 메트릭 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34ce912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = RNN(args.input_size, args.hidden_size, args.num_layers, args.output_size).to(args.device)\n",
    "\n",
    "# Build optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "# Build scheduler\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, args.epochs  * 37)\n",
    "\n",
    "# Build loss function + Build metric function\n",
    "if(args.learn_type == \"classification\"):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    metric_fn = accuracy\n",
    "else:\n",
    "    loss_fn = nn.MSELoss()\n",
    "    metric_fn = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac16dcc",
   "metadata": {},
   "source": [
    "### 3) loggger 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e916d883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build logger\n",
    "train_logger = SummaryWriter(f'{args.logs}/train/{args.title}')\n",
    "test_logger = SummaryWriter(f'{args.logs}/test/{args.title}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd01be75",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ffc5f5",
   "metadata": {},
   "source": [
    "## - Person, SNSB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58a19bf",
   "metadata": {},
   "source": [
    "### 1) 데이터셋 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e8bfea",
   "metadata": {},
   "source": [
    "### 2) 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cd7e913",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㅡㅡㅡㅡㅡ[Person_dataset.dtypes]ㅡㅡㅡㅡㅡ\n",
      "번호        int64\n",
      "성명 코드    object\n",
      "집단       object\n",
      "성별       object\n",
      "나이        int64\n",
      "교육연한      int64\n",
      "dtype: object\n",
      "ㅡㅡㅡㅡㅡ[SNSB_dataset.dtypes]ㅡㅡㅡㅡㅡ\n",
      "번호                    float64\n",
      "성명 코드                  object\n",
      "집단                     object\n",
      "DST_F+B               float64\n",
      "S-K-BNT               float64\n",
      "RCFT_copyscore        float64\n",
      "SVLT_delayedrecall    float64\n",
      "K-TMT-E_B             float64\n",
      "Unnamed: 8            float64\n",
      "Unnamed: 9            float64\n",
      "Unnamed: 10           float64\n",
      "Unnamed: 11           float64\n",
      "Unnamed: 12           float64\n",
      "Unnamed: 13           float64\n",
      "Unnamed: 14           float64\n",
      "Unnamed: 15           float64\n",
      "Unnamed: 16           float64\n",
      "Unnamed: 17           float64\n",
      "Unnamed: 18           float64\n",
      "Unnamed: 19           float64\n",
      "Unnamed: 20           float64\n",
      "Unnamed: 21           float64\n",
      "Unnamed: 22           float64\n",
      "Unnamed: 23           float64\n",
      "Unnamed: 24           float64\n",
      "Unnamed: 25           float64\n",
      "Unnamed: 26           float64\n",
      "Unnamed: 27           float64\n",
      "Unnamed: 28           float64\n",
      "Unnamed: 29           float64\n",
      "Unnamed: 30           float64\n",
      "Unnamed: 31           float64\n",
      "Unnamed: 32           float64\n",
      "Unnamed: 33           float64\n",
      "Unnamed: 34           float64\n",
      "Unnamed: 35           float64\n",
      "Unnamed: 36           float64\n",
      "Unnamed: 37           float64\n",
      "Unnamed: 38           float64\n",
      "Unnamed: 39           float64\n",
      "Unnamed: 40           float64\n",
      "Unnamed: 41           float64\n",
      "Unnamed: 42           float64\n",
      "Unnamed: 43           float64\n",
      "Unnamed: 44           float64\n",
      "Unnamed: 45           float64\n",
      "Unnamed: 46           float64\n",
      "Unnamed: 47           float64\n",
      "Unnamed: 48           float64\n",
      "Unnamed: 49           float64\n",
      "Unnamed: 50           float64\n",
      "Unnamed: 51           float64\n",
      "Unnamed: 52           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 불러오기 + 출력\n",
    "Person_path = f'C:\\\\Users\\\\Bang\\\\JupyterProjects\\\\VEEM_Project\\\\data\\\\Person_SNSB\\\\VEEM 대상자 정보.csv'\n",
    "SNSB_path = f'C:\\\\Users\\\\Bang\\\\JupyterProjects\\\\VEEM_Project\\\\data\\\\Person_SNSB\\\\VEEM SNSB 데이터.csv'\n",
    "\n",
    "Person_dataset=pd.read_csv(Person_path)\n",
    "SNSB_dataset=pd.read_csv(SNSB_path)\n",
    "\n",
    "print(\"ㅡㅡㅡㅡㅡ[Person_dataset.dtypes]ㅡㅡㅡㅡㅡ\")\n",
    "print(Person_dataset.dtypes)\n",
    "print(\"ㅡㅡㅡㅡㅡ[SNSB_dataset.dtypes]ㅡㅡㅡㅡㅡ\")\n",
    "print(SNSB_dataset.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a820279",
   "metadata": {},
   "source": [
    "### 3) 데이터 자료형 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a59b8e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㅡㅡㅡㅡㅡ[Person_dataset.dtypes]ㅡㅡㅡㅡㅡ\n",
      "번호         int64\n",
      "성명 코드     object\n",
      "집단        object\n",
      "성별        object\n",
      "나이       float64\n",
      "교육연한     float64\n",
      "dtype: object\n",
      "ㅡㅡㅡㅡㅡ[SNSB_dataset.dtypes]ㅡㅡㅡㅡㅡ\n",
      "번호                    float64\n",
      "성명 코드                  object\n",
      "집단                     object\n",
      "DST_F+B               float64\n",
      "S-K-BNT               float64\n",
      "RCFT_copyscore        float64\n",
      "SVLT_delayedrecall    float64\n",
      "K-TMT-E_B             float64\n",
      "Unnamed: 8            float64\n",
      "Unnamed: 9            float64\n",
      "Unnamed: 10           float64\n",
      "Unnamed: 11           float64\n",
      "Unnamed: 12           float64\n",
      "Unnamed: 13           float64\n",
      "Unnamed: 14           float64\n",
      "Unnamed: 15           float64\n",
      "Unnamed: 16           float64\n",
      "Unnamed: 17           float64\n",
      "Unnamed: 18           float64\n",
      "Unnamed: 19           float64\n",
      "Unnamed: 20           float64\n",
      "Unnamed: 21           float64\n",
      "Unnamed: 22           float64\n",
      "Unnamed: 23           float64\n",
      "Unnamed: 24           float64\n",
      "Unnamed: 25           float64\n",
      "Unnamed: 26           float64\n",
      "Unnamed: 27           float64\n",
      "Unnamed: 28           float64\n",
      "Unnamed: 29           float64\n",
      "Unnamed: 30           float64\n",
      "Unnamed: 31           float64\n",
      "Unnamed: 32           float64\n",
      "Unnamed: 33           float64\n",
      "Unnamed: 34           float64\n",
      "Unnamed: 35           float64\n",
      "Unnamed: 36           float64\n",
      "Unnamed: 37           float64\n",
      "Unnamed: 38           float64\n",
      "Unnamed: 39           float64\n",
      "Unnamed: 40           float64\n",
      "Unnamed: 41           float64\n",
      "Unnamed: 42           float64\n",
      "Unnamed: 43           float64\n",
      "Unnamed: 44           float64\n",
      "Unnamed: 45           float64\n",
      "Unnamed: 46           float64\n",
      "Unnamed: 47           float64\n",
      "Unnamed: 48           float64\n",
      "Unnamed: 49           float64\n",
      "Unnamed: 50           float64\n",
      "Unnamed: 51           float64\n",
      "Unnamed: 52           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "Person_dataset['나이'] = Person_dataset['나이'].astype(float)\n",
    "Person_dataset['교육연한'] = Person_dataset['교육연한'].astype(float)\n",
    "\n",
    "SNSB_dataset['DST_F+B'] = SNSB_dataset['DST_F+B'].astype(float)\n",
    "SNSB_dataset['S-K-BNT'] = SNSB_dataset['S-K-BNT'].astype(float)\n",
    "SNSB_dataset['SVLT_delayedrecall'] = SNSB_dataset['SVLT_delayedrecall'].astype(float)\n",
    "SNSB_dataset['K-TMT-E_B'] = SNSB_dataset['K-TMT-E_B'].astype(float)\n",
    "\n",
    "print(\"ㅡㅡㅡㅡㅡ[Person_dataset.dtypes]ㅡㅡㅡㅡㅡ\")\n",
    "print(Person_dataset.dtypes)\n",
    "print(\"ㅡㅡㅡㅡㅡ[SNSB_dataset.dtypes]ㅡㅡㅡㅡㅡ\")\n",
    "print(SNSB_dataset.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ecd35",
   "metadata": {},
   "source": [
    "### 4) 인덱스 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "030c4e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "Person_dataset.set_index('번호', inplace=True)\n",
    "SNSB_dataset.set_index('번호', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9f40e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㅡㅡㅡㅡㅡ[Person_dataset]ㅡㅡㅡㅡㅡ\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>성명 코드</th>\n",
       "      <th>집단</th>\n",
       "      <th>성별</th>\n",
       "      <th>나이</th>\n",
       "      <th>교육연한</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>번호</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NSU1</td>\n",
       "      <td>HC</td>\n",
       "      <td>여성</td>\n",
       "      <td>71.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSR1</td>\n",
       "      <td>HC</td>\n",
       "      <td>남성</td>\n",
       "      <td>73.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KMO1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>여성</td>\n",
       "      <td>59.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LCH1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>남성</td>\n",
       "      <td>83.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LYH1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>여성</td>\n",
       "      <td>67.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MYG1</td>\n",
       "      <td>HC</td>\n",
       "      <td>남성</td>\n",
       "      <td>60.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>YHR1</td>\n",
       "      <td>HC</td>\n",
       "      <td>남성</td>\n",
       "      <td>79.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LJG1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>남성</td>\n",
       "      <td>69.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PHG1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>남성</td>\n",
       "      <td>86.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SGS1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>남성</td>\n",
       "      <td>57.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KSO1</td>\n",
       "      <td>HC</td>\n",
       "      <td>여성</td>\n",
       "      <td>70.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LSO1</td>\n",
       "      <td>HC</td>\n",
       "      <td>남성</td>\n",
       "      <td>79.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LJH1</td>\n",
       "      <td>HC</td>\n",
       "      <td>여성</td>\n",
       "      <td>33.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KMS1</td>\n",
       "      <td>HC</td>\n",
       "      <td>여성</td>\n",
       "      <td>61.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KYT1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>남성</td>\n",
       "      <td>78.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PSA1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>여성</td>\n",
       "      <td>71.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>JHN1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>여성</td>\n",
       "      <td>59.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PJN1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>남성</td>\n",
       "      <td>78.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LTS1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>여성</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LJS1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>남성</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LYC1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>남성</td>\n",
       "      <td>82.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>YGY1</td>\n",
       "      <td>HC</td>\n",
       "      <td>남성</td>\n",
       "      <td>77.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>KJI1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>여성</td>\n",
       "      <td>78.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LSW1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>남성</td>\n",
       "      <td>51.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>KKS1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>남성</td>\n",
       "      <td>59.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>KTS1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>남성</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>PKS1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>남성</td>\n",
       "      <td>70.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>KSG1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>남성</td>\n",
       "      <td>77.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>JSY1</td>\n",
       "      <td>HC</td>\n",
       "      <td>여성</td>\n",
       "      <td>73.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>JHS1</td>\n",
       "      <td>HC</td>\n",
       "      <td>남성</td>\n",
       "      <td>73.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>KEH1</td>\n",
       "      <td>HC</td>\n",
       "      <td>여성</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PJJ1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>여성</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>KST1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>남성</td>\n",
       "      <td>87.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>CGY1</td>\n",
       "      <td>HC</td>\n",
       "      <td>남성</td>\n",
       "      <td>77.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>LHJ1</td>\n",
       "      <td>HC</td>\n",
       "      <td>여성</td>\n",
       "      <td>76.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>JJS1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>여성</td>\n",
       "      <td>75.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>LJW1</td>\n",
       "      <td>HC</td>\n",
       "      <td>남성</td>\n",
       "      <td>78.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   성명 코드   집단  성별    나이  교육연한\n",
       "번호                           \n",
       "2   NSU1   HC  여성  71.0  16.0\n",
       "3   CSR1   HC  남성  73.0  16.0\n",
       "4   KMO1  MCI  여성  59.0  12.0\n",
       "6   LCH1  MCI  남성  83.0  14.0\n",
       "7   LYH1  MCI  여성  67.0  15.0\n",
       "8   MYG1   HC  남성  60.0  16.0\n",
       "9   YHR1   HC  남성  79.0  16.0\n",
       "10  LJG1  MCI  남성  69.0  12.0\n",
       "11  PHG1  MCI  남성  86.0  12.0\n",
       "12  SGS1  MCI  남성  57.0   9.0\n",
       "13  KSO1   HC  여성  70.0   9.0\n",
       "14  LSO1   HC  남성  79.0   3.0\n",
       "15  LJH1   HC  여성  33.0  12.0\n",
       "16  KMS1   HC  여성  61.0   9.0\n",
       "17  KYT1  MCI  남성  78.0  16.0\n",
       "18  PSA1  MCI  여성  71.0  16.0\n",
       "19  JHN1  MCI  여성  59.0   6.0\n",
       "20  PJN1  MCI  남성  78.0   5.0\n",
       "21  LTS1  MCI  여성  81.0   0.0\n",
       "22  LJS1  MCI  남성  74.0   0.0\n",
       "23  LYC1  MCI  남성  82.0  10.0\n",
       "24  YGY1   HC  남성  77.0  16.0\n",
       "25  KJI1  MCI  여성  78.0   6.0\n",
       "27  LSW1  MCI  남성  51.0  12.0\n",
       "28  KKS1  MCI  남성  59.0  12.0\n",
       "29  KTS1  MCI  남성  80.0   9.0\n",
       "30  PKS1  MCI  남성  70.0  12.0\n",
       "31  KSG1  MCI  남성  77.0  16.0\n",
       "32  JSY1   HC  여성  73.0  12.0\n",
       "33  JHS1   HC  남성  73.0  16.0\n",
       "34  KEH1   HC  여성  72.0  16.0\n",
       "35  PJJ1  MCI  여성  70.0   0.0\n",
       "36  KST1  MCI  남성  87.0  17.0\n",
       "37  CGY1   HC  남성  77.0   9.0\n",
       "38  LHJ1   HC  여성  76.0   6.0\n",
       "39  JJS1  MCI  여성  75.0   6.0\n",
       "40  LJW1   HC  남성  78.0  16.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"ㅡㅡㅡㅡㅡ[Person_dataset]ㅡㅡㅡㅡㅡ\")\n",
    "Person_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39186fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㅡㅡㅡㅡㅡ[SNSB_dataset]ㅡㅡㅡㅡㅡ\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>성명 코드</th>\n",
       "      <th>집단</th>\n",
       "      <th>DST_F+B</th>\n",
       "      <th>S-K-BNT</th>\n",
       "      <th>RCFT_copyscore</th>\n",
       "      <th>SVLT_delayedrecall</th>\n",
       "      <th>K-TMT-E_B</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 43</th>\n",
       "      <th>Unnamed: 44</th>\n",
       "      <th>Unnamed: 45</th>\n",
       "      <th>Unnamed: 46</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>Unnamed: 48</th>\n",
       "      <th>Unnamed: 49</th>\n",
       "      <th>Unnamed: 50</th>\n",
       "      <th>Unnamed: 51</th>\n",
       "      <th>Unnamed: 52</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>번호</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>NSU1</td>\n",
       "      <td>HC</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>CSR1</td>\n",
       "      <td>HC</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>KMO1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>LCH1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>LYH1</td>\n",
       "      <td>MCI</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    성명 코드   집단  DST_F+B  S-K-BNT  RCFT_copyscore  SVLT_delayedrecall  \\\n",
       "번호                                                                     \n",
       "2.0  NSU1   HC     13.0     11.0            35.0                11.0   \n",
       "3.0  CSR1   HC     10.0     15.0            30.0                 5.0   \n",
       "4.0  KMO1  MCI      4.0     11.0            35.0                 1.0   \n",
       "6.0  LCH1  MCI      5.0      8.0            18.5                 0.0   \n",
       "7.0  LYH1  MCI     12.0     10.0            36.0                 7.0   \n",
       "..    ...  ...      ...      ...             ...                 ...   \n",
       "NaN   NaN  NaN      NaN      NaN             NaN                 NaN   \n",
       "NaN   NaN  NaN      NaN      NaN             NaN                 NaN   \n",
       "NaN   NaN  NaN      NaN      NaN             NaN                 NaN   \n",
       "NaN   NaN  NaN      NaN      NaN             NaN                 NaN   \n",
       "NaN   NaN  NaN      NaN      NaN             NaN                 NaN   \n",
       "\n",
       "     K-TMT-E_B  Unnamed: 8  Unnamed: 9  Unnamed: 10  ...  Unnamed: 43  \\\n",
       "번호                                                   ...                \n",
       "2.0       16.0         NaN         NaN          NaN  ...          NaN   \n",
       "3.0       26.0         NaN         NaN          NaN  ...          NaN   \n",
       "4.0       50.0         NaN         NaN          NaN  ...          NaN   \n",
       "6.0      300.0         NaN         NaN          NaN  ...          NaN   \n",
       "7.0       36.0         NaN         NaN          NaN  ...          NaN   \n",
       "..         ...         ...         ...          ...  ...          ...   \n",
       "NaN        NaN         NaN         NaN          NaN  ...          NaN   \n",
       "NaN        NaN         NaN         NaN          NaN  ...          NaN   \n",
       "NaN        NaN         NaN         NaN          NaN  ...          NaN   \n",
       "NaN        NaN         NaN         NaN          NaN  ...          NaN   \n",
       "NaN        NaN         NaN         NaN          NaN  ...          NaN   \n",
       "\n",
       "     Unnamed: 44  Unnamed: 45  Unnamed: 46  Unnamed: 47  Unnamed: 48  \\\n",
       "번호                                                                     \n",
       "2.0          NaN          NaN          NaN          NaN          NaN   \n",
       "3.0          NaN          NaN          NaN          NaN          NaN   \n",
       "4.0          NaN          NaN          NaN          NaN          NaN   \n",
       "6.0          NaN          NaN          NaN          NaN          NaN   \n",
       "7.0          NaN          NaN          NaN          NaN          NaN   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "NaN          NaN          NaN          NaN          NaN          NaN   \n",
       "NaN          NaN          NaN          NaN          NaN          NaN   \n",
       "NaN          NaN          NaN          NaN          NaN          NaN   \n",
       "NaN          NaN          NaN          NaN          NaN          NaN   \n",
       "NaN          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "     Unnamed: 49  Unnamed: 50  Unnamed: 51  Unnamed: 52  \n",
       "번호                                                       \n",
       "2.0          NaN          NaN          NaN          NaN  \n",
       "3.0          NaN          NaN          NaN          NaN  \n",
       "4.0          NaN          NaN          NaN          NaN  \n",
       "6.0          NaN          NaN          NaN          NaN  \n",
       "7.0          NaN          NaN          NaN          NaN  \n",
       "..           ...          ...          ...          ...  \n",
       "NaN          NaN          NaN          NaN          NaN  \n",
       "NaN          NaN          NaN          NaN          NaN  \n",
       "NaN          NaN          NaN          NaN          NaN  \n",
       "NaN          NaN          NaN          NaN          NaN  \n",
       "NaN          NaN          NaN          NaN          NaN  \n",
       "\n",
       "[999 rows x 52 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"ㅡㅡㅡㅡㅡ[SNSB_dataset]ㅡㅡㅡㅡㅡ\")\n",
    "SNSB_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d24dab",
   "metadata": {},
   "source": [
    "### 5) 필요한 피쳐 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "462d91e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 데이터셋 나누기\n",
    "SNSB_all_dataset=SNSB_dataset.iloc[:, 2:7]\n",
    "SNSB_all_dataset = SNSB_all_dataset.dropna(axis = 0)\n",
    "Person_all_dataset=Person_dataset.iloc[:, 2:]\n",
    "Person_dementia_dataset=Person_dataset.iloc[:, 1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e4c83ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㅡㅡㅡㅡㅡ[SNSB_all_dataset]ㅡㅡㅡㅡㅡ\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DST_F+B</th>\n",
       "      <th>S-K-BNT</th>\n",
       "      <th>RCFT_copyscore</th>\n",
       "      <th>SVLT_delayedrecall</th>\n",
       "      <th>K-TMT-E_B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>번호</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25.0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31.0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32.0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33.0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34.0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36.0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37.0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38.0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39.0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40.0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DST_F+B  S-K-BNT  RCFT_copyscore  SVLT_delayedrecall  K-TMT-E_B\n",
       "번호                                                                   \n",
       "2.0      13.0     11.0            35.0                11.0       16.0\n",
       "3.0      10.0     15.0            30.0                 5.0       26.0\n",
       "4.0       4.0     11.0            35.0                 1.0       50.0\n",
       "6.0       5.0      8.0            18.5                 0.0      300.0\n",
       "7.0      12.0     10.0            36.0                 7.0       36.0\n",
       "8.0      11.0     13.0            36.0                 6.0       20.0\n",
       "9.0      11.0     13.0            34.0                 7.0       32.0\n",
       "10.0      9.0     12.0            27.0                 0.0       43.0\n",
       "11.0      8.0      9.0            28.0                 0.0       90.0\n",
       "12.0      7.0     11.0            26.0                 0.0      121.0\n",
       "13.0     10.0     13.0            32.5                 5.0       32.0\n",
       "14.0      7.0     13.0            28.0                 4.0       52.0\n",
       "15.0     12.0     13.0            36.0                10.0       16.0\n",
       "16.0      9.0     13.0            31.0                 7.0       61.0\n",
       "17.0      8.0     13.0            35.0                 2.0       48.0\n",
       "18.0      9.0     11.0            31.0                 1.0       39.0\n",
       "19.0     11.0     12.0            35.0                 4.0       40.0\n",
       "20.0      5.0     10.0            20.0                 4.0      300.0\n",
       "21.0      7.0      5.0            25.5                 4.0      300.0\n",
       "22.0      9.0     13.0            16.0                 0.0       77.0\n",
       "23.0      9.0      9.0            18.5                 2.0      300.0\n",
       "24.0     10.0     14.0            36.0                 7.0       20.0\n",
       "25.0      8.0     10.0            20.0                 2.0      300.0\n",
       "27.0     12.0     13.0            34.0                 0.0       22.0\n",
       "28.0      9.0     13.0            29.5                 9.0       31.0\n",
       "29.0      9.0     10.0            20.5                 4.0       67.0\n",
       "30.0     10.0     15.0            35.0                 8.0       28.0\n",
       "31.0     11.0     14.0            34.0                 2.0       67.0\n",
       "32.0     10.0     13.0            33.0                10.0       42.0\n",
       "33.0     14.0     12.0            31.0                 5.0       44.0\n",
       "34.0     11.0     11.0            36.0                 5.0       54.0\n",
       "35.0      6.0     11.0            18.0                 4.0      145.0\n",
       "36.0     10.0      7.0            29.0                 4.0       96.0\n",
       "37.0     10.0     12.0            34.0                 5.0       24.0\n",
       "38.0      7.0     14.0            31.0                10.0       20.0\n",
       "39.0     10.0      8.0            17.5                 0.0      116.0\n",
       "40.0     10.0     14.0            32.0                 4.0       29.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"ㅡㅡㅡㅡㅡ[SNSB_all_dataset]ㅡㅡㅡㅡㅡ\")\n",
    "SNSB_all_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "269e575c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㅡㅡㅡㅡㅡ[Person_all_dataset]ㅡㅡㅡㅡㅡ\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>성별</th>\n",
       "      <th>나이</th>\n",
       "      <th>교육연한</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>번호</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>여성</td>\n",
       "      <td>71.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>남성</td>\n",
       "      <td>73.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>여성</td>\n",
       "      <td>59.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>남성</td>\n",
       "      <td>83.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>여성</td>\n",
       "      <td>67.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>남성</td>\n",
       "      <td>60.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>남성</td>\n",
       "      <td>79.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>남성</td>\n",
       "      <td>69.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>남성</td>\n",
       "      <td>86.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>남성</td>\n",
       "      <td>57.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>여성</td>\n",
       "      <td>70.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>남성</td>\n",
       "      <td>79.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>여성</td>\n",
       "      <td>33.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>여성</td>\n",
       "      <td>61.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>남성</td>\n",
       "      <td>78.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>여성</td>\n",
       "      <td>71.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>여성</td>\n",
       "      <td>59.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>남성</td>\n",
       "      <td>78.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>여성</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>남성</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>남성</td>\n",
       "      <td>82.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>남성</td>\n",
       "      <td>77.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>여성</td>\n",
       "      <td>78.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>남성</td>\n",
       "      <td>51.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>남성</td>\n",
       "      <td>59.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>남성</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>남성</td>\n",
       "      <td>70.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>남성</td>\n",
       "      <td>77.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>여성</td>\n",
       "      <td>73.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>남성</td>\n",
       "      <td>73.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>여성</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>여성</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>남성</td>\n",
       "      <td>87.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>남성</td>\n",
       "      <td>77.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>여성</td>\n",
       "      <td>76.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>여성</td>\n",
       "      <td>75.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>남성</td>\n",
       "      <td>78.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    성별    나이  교육연한\n",
       "번호                \n",
       "2   여성  71.0  16.0\n",
       "3   남성  73.0  16.0\n",
       "4   여성  59.0  12.0\n",
       "6   남성  83.0  14.0\n",
       "7   여성  67.0  15.0\n",
       "8   남성  60.0  16.0\n",
       "9   남성  79.0  16.0\n",
       "10  남성  69.0  12.0\n",
       "11  남성  86.0  12.0\n",
       "12  남성  57.0   9.0\n",
       "13  여성  70.0   9.0\n",
       "14  남성  79.0   3.0\n",
       "15  여성  33.0  12.0\n",
       "16  여성  61.0   9.0\n",
       "17  남성  78.0  16.0\n",
       "18  여성  71.0  16.0\n",
       "19  여성  59.0   6.0\n",
       "20  남성  78.0   5.0\n",
       "21  여성  81.0   0.0\n",
       "22  남성  74.0   0.0\n",
       "23  남성  82.0  10.0\n",
       "24  남성  77.0  16.0\n",
       "25  여성  78.0   6.0\n",
       "27  남성  51.0  12.0\n",
       "28  남성  59.0  12.0\n",
       "29  남성  80.0   9.0\n",
       "30  남성  70.0  12.0\n",
       "31  남성  77.0  16.0\n",
       "32  여성  73.0  12.0\n",
       "33  남성  73.0  16.0\n",
       "34  여성  72.0  16.0\n",
       "35  여성  70.0   0.0\n",
       "36  남성  87.0  17.0\n",
       "37  남성  77.0   9.0\n",
       "38  여성  76.0   6.0\n",
       "39  여성  75.0   6.0\n",
       "40  남성  78.0  16.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"ㅡㅡㅡㅡㅡ[Person_all_dataset]ㅡㅡㅡㅡㅡ\")\n",
    "Person_all_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e60f1b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㅡㅡㅡㅡㅡ[Person_dementia_dataset]ㅡㅡㅡㅡㅡ\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>집단</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>번호</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MCI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     집단\n",
       "번호     \n",
       "2    HC\n",
       "3    HC\n",
       "4   MCI\n",
       "6   MCI\n",
       "7   MCI\n",
       "8    HC\n",
       "9    HC\n",
       "10  MCI\n",
       "11  MCI\n",
       "12  MCI\n",
       "13   HC\n",
       "14   HC\n",
       "15   HC\n",
       "16   HC\n",
       "17  MCI\n",
       "18  MCI\n",
       "19  MCI\n",
       "20  MCI\n",
       "21  MCI\n",
       "22  MCI\n",
       "23  MCI\n",
       "24   HC\n",
       "25  MCI\n",
       "27  MCI\n",
       "28  MCI\n",
       "29  MCI\n",
       "30  MCI\n",
       "31  MCI\n",
       "32   HC\n",
       "33   HC\n",
       "34   HC\n",
       "35  MCI\n",
       "36  MCI\n",
       "37   HC\n",
       "38   HC\n",
       "39  MCI\n",
       "40   HC"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"ㅡㅡㅡㅡㅡ[Person_dementia_dataset]ㅡㅡㅡㅡㅡ\")\n",
    "Person_dementia_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aba0348",
   "metadata": {},
   "source": [
    "### 6) 데이터 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbd4eb6",
   "metadata": {},
   "source": [
    "#### (1) Person_dementia_dataset : pandas -> list -> 문자열 임베딩 -> torch 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1afc0eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person_dementia_dataset_list :  ['HC', 'HC', 'MCI', 'MCI', 'MCI', 'HC', 'HC', 'MCI', 'MCI', 'MCI', 'HC', 'HC', 'HC', 'HC', 'MCI', 'MCI', 'MCI', 'MCI', 'MCI', 'MCI', 'MCI', 'HC', 'MCI', 'MCI', 'MCI', 'MCI', 'MCI', 'MCI', 'HC', 'HC', 'HC', 'MCI', 'MCI', 'HC', 'HC', 'MCI', 'HC']\n",
      "Person_dementia_dataset_embedding_list :  [0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0]\n",
      "Person_dementia_dataset_torch :  tensor([0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
      "        0.])\n"
     ]
    }
   ],
   "source": [
    "# for idx in Person_dementia_dataset.index:\n",
    "#     print(Person_dementia_dataset.loc[idx,'집단'])\n",
    "\n",
    "# pandas -> list\n",
    "Person_dementia_dataset_list = Person_dementia_dataset['집단'].values.tolist()\n",
    "print(\"Person_dementia_dataset_list : \", Person_dementia_dataset_list)\n",
    "\n",
    "# list -> 문자열 임베딩\n",
    "embedding_table = {'HC': 0, 'MCI': 1}\n",
    "Person_dementia_dataset_embedding_list = []\n",
    "for i, word in enumerate(Person_dementia_dataset_list):\n",
    "    Person_dementia_dataset_embedding_list.append(embedding_table[word])\n",
    "print(\"Person_dementia_dataset_embedding_list : \", Person_dementia_dataset_embedding_list)\n",
    "\n",
    "# list -> torch 변환\n",
    "Person_dementia_dataset_torch = torch.Tensor(Person_dementia_dataset_embedding_list)\n",
    "print(\"Person_dementia_dataset_torch : \", Person_dementia_dataset_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257d0eda",
   "metadata": {},
   "source": [
    "#### (2) SNSB_all_dataset : pandas -> numpy -> torch 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5aff0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"ㅡㅡㅡㅡㅡ[SNSB_all_dataset_torch.shape]ㅡㅡㅡㅡㅡ\")\\nprint(SNSB_all_dataset_torch.shape)\\n\\nprint(\"ㅡㅡㅡㅡㅡ[SNSB_all_dataset_torch]ㅡㅡㅡㅡㅡ\")\\nprint(SNSB_all_dataset_torch)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SNSB_all_dataset_np = SNSB_all_dataset.to_numpy()\n",
    "SNSB_all_dataset_torch = torch.from_numpy(SNSB_all_dataset_np).float()\n",
    "\"\"\"\n",
    "print(\"ㅡㅡㅡㅡㅡ[SNSB_all_dataset_torch.shape]ㅡㅡㅡㅡㅡ\")\n",
    "print(SNSB_all_dataset_torch.shape)\n",
    "\n",
    "print(\"ㅡㅡㅡㅡㅡ[SNSB_all_dataset_torch]ㅡㅡㅡㅡㅡ\")\n",
    "print(SNSB_all_dataset_torch)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9fdf28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Person_all_dataset_np = Person_all_dataset.to_numpy()\n",
    "# Person_all_dataset_torch = torch.from_numpy(Person_all_dataset_np).float()\n",
    "\n",
    "# print(\"ㅡㅡㅡㅡㅡ[Person_all_dataset_torch.shape]ㅡㅡㅡㅡㅡ\")\n",
    "# print(Person_all_dataset_torch.shape)\n",
    "\n",
    "# print(\"ㅡㅡㅡㅡㅡ[Person_all_dataset_torch]ㅡㅡㅡㅡㅡ\")\n",
    "# print(Person_all_dataset_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199977fb",
   "metadata": {},
   "source": [
    "## - eyerpt, rpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0bff87",
   "metadata": {},
   "source": [
    "### 1) 데이터셋 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb7936",
   "metadata": {},
   "source": [
    "### 2) 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23070805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eyerpt_rpt_files_name :  ['02_eyerpt.csv', '02_rpt.csv', '03_eyerpt.csv', '03_rpt.csv', '04_eyerpt.csv', '04_rpt.csv', '06_eyerpt.csv', '06_rpt.csv', '07_eyerpt.csv', '07_rpt.csv', '08_eyerpt.csv', '08_rpt.csv', '09_eyerpt.csv', '09_rpt.csv', '10_eyerpt.csv', '10_rpt.csv', '11_eyerpt.csv', '11_rpt.csv', '12_eyerpt.csv', '12_rpt.csv', '13_eyerpt.csv', '13_rpt.csv', '14_eyerpt.csv', '14_rpt.csv', '15_eyerpt.csv', '15_rpt.csv', '16_eyerpt.csv', '16_rpt.csv', '17_eyerpt.csv', '17_rpt.csv', '18_eyerpt.csv', '18_rpt.csv', '19_eyerpt.csv', '19_rpt.csv', '20_eyerpt.csv', '20_rpt.csv', '21_eyerpt.csv', '21_rpt.csv', '22_eyerpt.csv', '22_rpt.csv', '23_eyerpt.csv', '23_rpt.csv', '24_eyerpt.csv', '24_rpt.csv', '25_eyerpt.csv', '25_rpt.csv', '27_eyerpt.csv', '27_rpt.csv', '28_eyerpt.csv', '28_rpt.csv', '29_eyerpt.csv', '29_rpt.csv', '30_eyerpt.csv', '30_rpt.csv', '31_eyerpt.csv', '31_rpt.csv', '32_eyerpt.csv', '32_rpt.csv', '33_eyerpt.csv', '33_rpt.csv', '34_eyerpt.csv', '34_rpt.csv', '35_eyerpt.csv', '35_rpt.csv', '36_eyerpt.csv', '36_rpt.csv', '37_eyerpt.csv', '37_rpt.csv', '38_eyerpt.csv', '38_rpt.csv', '39_eyerpt.csv', '39_rpt.csv', '40_eyerpt.csv', '40_rpt.csv']\n",
      "eyerpt_files_name :  ['02_eyerpt.csv', '03_eyerpt.csv', '04_eyerpt.csv', '06_eyerpt.csv', '07_eyerpt.csv', '08_eyerpt.csv', '09_eyerpt.csv', '10_eyerpt.csv', '11_eyerpt.csv', '12_eyerpt.csv', '13_eyerpt.csv', '14_eyerpt.csv', '15_eyerpt.csv', '16_eyerpt.csv', '17_eyerpt.csv', '18_eyerpt.csv', '19_eyerpt.csv', '20_eyerpt.csv', '21_eyerpt.csv', '22_eyerpt.csv', '23_eyerpt.csv', '24_eyerpt.csv', '25_eyerpt.csv', '27_eyerpt.csv', '28_eyerpt.csv', '29_eyerpt.csv', '30_eyerpt.csv', '31_eyerpt.csv', '32_eyerpt.csv', '33_eyerpt.csv', '34_eyerpt.csv', '35_eyerpt.csv', '36_eyerpt.csv', '37_eyerpt.csv', '38_eyerpt.csv', '39_eyerpt.csv', '40_eyerpt.csv']\n",
      "rpt_files_name :  ['02_rpt.csv', '03_rpt.csv', '04_rpt.csv', '06_rpt.csv', '07_rpt.csv', '08_rpt.csv', '09_rpt.csv', '10_rpt.csv', '11_rpt.csv', '12_rpt.csv', '13_rpt.csv', '14_rpt.csv', '15_rpt.csv', '16_rpt.csv', '17_rpt.csv', '18_rpt.csv', '19_rpt.csv', '20_rpt.csv', '21_rpt.csv', '22_rpt.csv', '23_rpt.csv', '24_rpt.csv', '25_rpt.csv', '27_rpt.csv', '28_rpt.csv', '29_rpt.csv', '30_rpt.csv', '31_rpt.csv', '32_rpt.csv', '33_rpt.csv', '34_rpt.csv', '35_rpt.csv', '36_rpt.csv', '37_rpt.csv', '38_rpt.csv', '39_rpt.csv', '40_rpt.csv']\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터셋 정보\n",
    "train_eyerpt_all_dataset = defaultdict(list)\n",
    "test_eyerpt_all_dataset = defaultdict(list)\n",
    "train_rpt_all_dataset = defaultdict(list)\n",
    "test_rpt_all_dataset = defaultdict(list)\n",
    "\n",
    "# 전체 경로\n",
    "eyerpt_rpt_path = f'C:\\\\Users\\\\Bang\\\\JupyterProjects\\\\VEEM_Project\\\\data\\\\rpt\\\\'\n",
    "\n",
    "# 전체 폴더 내 파일 리스트 추출\n",
    "eyerpt_rpt_files_name = os.listdir(eyerpt_rpt_path)\n",
    "eyerpt_rpt_files_name = sorted(eyerpt_rpt_files_name)\n",
    "\n",
    "print(\"eyerpt_rpt_files_name : \", eyerpt_rpt_files_name)\n",
    "\n",
    "# eyerpt, rpt 파일 리스트 추출\n",
    "eyerpt_files_name = [eyerpt_rpt_file_name for eyerpt_rpt_file_name in eyerpt_rpt_files_name if \"eye\" in eyerpt_rpt_file_name]\n",
    "rpt_files_name = [eyerpt_rpt_file_name for eyerpt_rpt_file_name in eyerpt_rpt_files_name if not \"eye\" in eyerpt_rpt_file_name]\n",
    "\n",
    "print(\"eyerpt_files_name : \", eyerpt_files_name)\n",
    "print(\"rpt_files_name : \", rpt_files_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5202b30d",
   "metadata": {},
   "source": [
    "### 3) train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d6ae851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"train_rpt_files_name : \", train_rpt_files_name)\\nprint(\"len(train_rpt_files_name) : \", len(train_rpt_files_name))\\nprint(\"test_rpt_files_name : \", test_rpt_files_name)\\nprint(\"len(test_rpt_files_name) : \", len(test_rpt_files_name))\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 데이터 개수 -> 비율 기반 split\n",
    "all_eyerpt_count = len(eyerpt_files_name)\n",
    "test_eyerpt_count = int(all_eyerpt_count * args.test_ratio)\n",
    "train_eyerpt_count = all_eyerpt_count - test_eyerpt_count\n",
    "\n",
    "train_eyerpt_files_name = eyerpt_files_name[:train_eyerpt_count]\n",
    "test_eyerpt_files_name = eyerpt_files_name[train_eyerpt_count:]\n",
    "\"\"\"\n",
    "print(\"train_eyerpt_files_name : \", train_eyerpt_files_name)\n",
    "print(\"len(train_eyerpt_files_name) : \", len(train_eyerpt_files_name))\n",
    "print(\"test_eyerpt_files_name : \", test_eyerpt_files_name)\n",
    "print(\"len(test_eyerpt_files_name) : \", len(test_eyerpt_files_name))\n",
    "\"\"\"\n",
    "\n",
    "all_rpt_count = len(rpt_files_name)\n",
    "test_rpt_count = int(all_rpt_count * args.test_ratio)\n",
    "train_rpt_count = all_rpt_count - test_rpt_count\n",
    "\n",
    "train_rpt_files_name = rpt_files_name[:train_rpt_count]\n",
    "test_rpt_files_name = rpt_files_name[train_rpt_count:]\n",
    "\"\"\"\n",
    "print(\"train_rpt_files_name : \", train_rpt_files_name)\n",
    "print(\"len(train_rpt_files_name) : \", len(train_rpt_files_name))\n",
    "print(\"test_rpt_files_name : \", test_rpt_files_name)\n",
    "print(\"len(test_rpt_files_name) : \", len(test_rpt_files_name))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030ac1c5",
   "metadata": {},
   "source": [
    "### 4) 전처리 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02356660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eyerpt 파일 전처리\n",
    "def eyerpt_rpt_preprocessing(name):\n",
    "    # =====================================================\n",
    "    # (1) 변수 불러오기\n",
    "    # =====================================================\n",
    "    print(\"name : \", name)\n",
    "    files_name = eval(f\"{name}_files_name\")\n",
    "    all_dataset = eval(f\"{name}_all_dataset\")\n",
    "\n",
    "    for i, file_name in enumerate(files_name):\n",
    "        # =====================================================\n",
    "        # (2) 데이터 불러오기\n",
    "        # =====================================================\n",
    "        path = eyerpt_rpt_path + file_name\n",
    "        \"\"\"\n",
    "        print('path : ', path) # 확인용 코드\n",
    "        \"\"\"\n",
    "\n",
    "        dataset=pd.read_csv(path)\n",
    "        \"\"\"\n",
    "        print(\"ㅡㅡㅡㅡㅡ[dataset.dtypes]ㅡㅡㅡㅡㅡ\")\n",
    "        print(dataset.dtypes)\n",
    "        \"\"\"\n",
    "\n",
    "        # =====================================================\n",
    "        # (3) 데이터 자료형 변환\n",
    "        # =====================================================\n",
    "\n",
    "        # =====================================================\n",
    "        # (4) 인덱스 지정\n",
    "        # =====================================================\n",
    "        # dataset['time stamp'] = pd.to_datetime(dataset['time stamp'])\n",
    "        dataset.set_index('time stamp', inplace=True)\n",
    "        \"\"\"\n",
    "        print(\"ㅡㅡㅡㅡㅡ[dataset]ㅡㅡㅡㅡㅡ\")\n",
    "        print(dataset)\n",
    "        \"\"\"\n",
    "\n",
    "        # =====================================================\n",
    "        # (5) 데이터 프레임 변환 + 필요한 피쳐 추출\n",
    "        # =====================================================\n",
    "        df = dataset.loc[:, :]\n",
    "        if(name == \"train_eyerpt\" or name == \"test_eyerpt\"):\n",
    "            df = df.drop(['time', 'beforeOBJ', 'presentOBJ', 'Obeject_name'], axis = 1) # 1 = columns\n",
    "        else:\n",
    "            df = df.drop(['total_task_time_s', 'hand_x_rotation_deg', 'hand_y_rotation_deg', 'hand_z_rotation_deg'], axis = 1)\n",
    "        \"\"\"\n",
    "        print(\"ㅡㅡㅡㅡㅡ[df]ㅡㅡㅡㅡㅡ\")\n",
    "        print(df)\n",
    "        \"\"\"\n",
    "\n",
    "        # =====================================================\n",
    "        # (6) 결측치 행 제거\n",
    "        # =====================================================\n",
    "        df.dropna(axis=0, inplace = True)\n",
    "        \"\"\"\n",
    "        print(\"ㅡㅡㅡㅡㅡ[df]ㅡㅡㅡㅡㅡ\")\n",
    "        print(df)\n",
    "        print(df.Panel_num)\n",
    "        \"\"\"\n",
    "\n",
    "        # =====================================================\n",
    "        # (7) 실험 종료 이후 데이터 제거\n",
    "        # =====================================================\n",
    "        if(name == \"train_eyerpt\" or name == \"test_eyerpt\"):\n",
    "            df_drop8 = df[df.Panel_num < 8]\n",
    "        else:\n",
    "            df_drop8 = df[df.panel_num < 8]\n",
    "        \"\"\"\n",
    "        print(\"ㅡㅡㅡㅡㅡ[df_drop8]ㅡㅡㅡㅡㅡ\")\n",
    "        print(df_drop8)\n",
    "        \"\"\"\n",
    "\n",
    "        # =====================================================\n",
    "        # (8) 데이터 프레임 -> numpy 변환 -> torch 변환\n",
    "        # =====================================================\n",
    "        if(name == \"train_eyerpt\" or name == \"test_eyerpt\"):\n",
    "            df_drop8_np = df_drop8.to_numpy()\n",
    "            df_drop8_torch = torch.from_numpy(df_drop8_np)\n",
    "        else:\n",
    "            df_drop8_np = df_drop8.to_numpy()\n",
    "            df_drop8_torch = torch.from_numpy(df_drop8_np).float()\n",
    "        \"\"\"\n",
    "        print(\"ㅡㅡㅡㅡㅡ[df_drop8_torch.shape]ㅡㅡㅡㅡㅡ\")\n",
    "        print(df_drop8_torch.shape)\n",
    "\n",
    "        print(\"ㅡㅡㅡㅡㅡ[df_drop8_torch]ㅡㅡㅡㅡㅡ\")\n",
    "        print(df_drop8_torch)\n",
    "        \"\"\"\n",
    "\n",
    "        # =====================================================\n",
    "        # (9) 데이터셋 길이 추출\n",
    "        # =====================================================\n",
    "        df_sequence_length = len(df_drop8_torch)\n",
    "        \"\"\"\n",
    "        print(\"df_sequence_length : \", df_sequence_length)\n",
    "        \"\"\"\n",
    "        \n",
    "        # =====================================================\n",
    "        # (10) 데이터셋 라벨 행 추출(float형 사용)\n",
    "        # =====================================================\n",
    "        if(args.learn_type == \"regression\"):\n",
    "            # =====================================================\n",
    "            # 1] SNSB 데이터셋 라벨 행 추출(float형 사용)\n",
    "            # =====================================================\n",
    "            SNSB_label = SNSB_all_dataset_torch[i,:]\n",
    "            \"\"\"\n",
    "            print(\"SNSB_label : \", SNSB_label)\n",
    "            \"\"\"\n",
    "            SNSB_label = SNSB_label.reshape(-1, len(SNSB_label)) # loss 학습을 위해 output과 형식 통일!!!\n",
    "            \"\"\"\n",
    "            print(\"SNSB_label : \", SNSB_label)\n",
    "            \"\"\"\n",
    "        else:\n",
    "            # =====================================================\n",
    "            # 2] Person_dementia 데이터셋 라벨 행 추출(float형 사용)\n",
    "            # =====================================================\n",
    "            Person_dementia_label = Person_dementia_dataset_torch[i]\n",
    "            \"\"\"\n",
    "            print(\"Person_dementia_label : \", Person_dementia_label)\n",
    "            \"\"\"\n",
    "            Person_dementia_label = Person_dementia_label.reshape(1) # loss 학습을 위해 output과 형식 통일!!!\n",
    "            \"\"\"\n",
    "            print(\"Person_dementia_label : \", Person_dementia_label)\n",
    "            \"\"\"\n",
    "\n",
    "        # =====================================================\n",
    "        # (11) 전체 데이터셋 구성\n",
    "        # =====================================================\n",
    "        # 파일 정보 + 파일 sequence 길이 리스트화\n",
    "        if(args.learn_type == \"regression\"):\n",
    "            df_infor = [df_drop8_torch, df_sequence_length, SNSB_label]\n",
    "        else:\n",
    "            df_infor = [df_drop8_torch, df_sequence_length, Person_dementia_label]\n",
    "        \"\"\"\n",
    "        print(\"df_infor : \", df_infor)\n",
    "        \"\"\"\n",
    "\n",
    "        # 모든 정보 딕셔너리화\n",
    "        all_dataset[file_name[0:2]].append(df_infor)\n",
    "        # *all_dataset = dict(zip([file_name[0:2]], df_infor))\n",
    "        \"\"\"\n",
    "        print(\"all_dataset['0'] : \", all_dataset['02'])\n",
    "        print(\"all_dataset : \", all_dataset)\n",
    "        \"\"\"\n",
    "\n",
    "    # =====================================================\n",
    "    # (12) 전체 데이터셋 return\n",
    "    # =====================================================\n",
    "    exec(f\"{name}_all_dataset = all_dataset\")\n",
    "\n",
    "    print(\"len(all_dataset) : \", len(eval(f\"{name}_all_dataset\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dbf6ba",
   "metadata": {},
   "source": [
    "### 5) 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2223d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name :  train_eyerpt\n",
      "len(all_dataset) :  28\n",
      "name :  test_eyerpt\n",
      "len(all_dataset) :  9\n",
      "name :  train_rpt\n",
      "len(all_dataset) :  28\n",
      "name :  test_rpt\n",
      "len(all_dataset) :  9\n",
      "len(train_eyerpt_all_dataset) :  28\n",
      "len(test_eyerpt_all_dataset) :  9\n",
      "len(train_rpt_all_dataset) :  28\n",
      "len(test_rpt_all_dataset) :  9\n"
     ]
    }
   ],
   "source": [
    "eyerpt_rpt_preprocessing(\"train_eyerpt\")\n",
    "eyerpt_rpt_preprocessing(\"test_eyerpt\")\n",
    "eyerpt_rpt_preprocessing(\"train_rpt\")\n",
    "eyerpt_rpt_preprocessing(\"test_rpt\")\n",
    "\n",
    "print(\"len(train_eyerpt_all_dataset) : \", len(train_eyerpt_all_dataset))\n",
    "print(\"len(test_eyerpt_all_dataset) : \", len(test_eyerpt_all_dataset))\n",
    "print(\"len(train_rpt_all_dataset) : \", len(train_rpt_all_dataset))\n",
    "print(\"len(test_rpt_all_dataset) : \", len(test_rpt_all_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13144fec",
   "metadata": {},
   "source": [
    "### 3) 데이터 자료형 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376aa6de",
   "metadata": {},
   "source": [
    "rpt_dataset['panel_num'] = rpt_dataset['panel_num'].astype(float)\n",
    "rpt_dataset['error'] = rpt_dataset['error'].astype(float)\n",
    "\n",
    "print(\"ㅡㅡㅡㅡㅡ[eyerpt_dataset.dtypes]ㅡㅡㅡㅡㅡ\")\n",
    "print(eyerpt_dataset.dtypes)\n",
    "print(\"ㅡㅡㅡㅡㅡ[rpt_dataset.dtypes]ㅡㅡㅡㅡㅡ\")\n",
    "print(rpt_dataset.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8596e3",
   "metadata": {},
   "source": [
    "## 5. Model Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc38c8c9",
   "metadata": {},
   "source": [
    "### 1) Load model epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc64b341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "start_epoch = 0\n",
    "if args.resume:\n",
    "    start_epoch = load_checkpoint(args.checkpoints, args.title, model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9e6a61",
   "metadata": {},
   "source": [
    "### 2) Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10a3b6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 1s\n",
      "\t Train Loss: 0.766 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.0002999983043633444\n",
      "Epoch: 02 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.764 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.0002999932174917131\n",
      "Epoch: 03 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.762 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.0002999847395001127\n",
      "Epoch: 04 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.759 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.00029997287058021775\n",
      "Epoch: 05 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.757 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.00029995761100036673\n",
      "Epoch: 06 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.755 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.0002999389611055553\n",
      "Epoch: 07 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.752 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.00029991692131742985\n",
      "Epoch: 08 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.750 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.0002998914921342763\n",
      "Epoch: 09 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.748 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.00029986267413101015\n",
      "Epoch: 10 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.746 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.000299830467959163\n",
      "Epoch: 11 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.744 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.0002997948743468677\n",
      "Epoch: 12 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.741 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.0002997558940988421\n",
      "Epoch: 13 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.739 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.0002997135280963705\n",
      "Epoch: 14 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.737 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.00029966777729728447\n",
      "Epoch: 15 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.735 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.0002996186427359402\n",
      "Epoch: 16 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.733 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.000299566125523196\n",
      "Epoch: 17 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.731 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.00029951022684638647\n",
      "Epoch: 18 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.729 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.0002994509479692963\n",
      "Epoch: 19 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.727 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.0002993882902321315\n",
      "Epoch: 20 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.725 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.00029932225505148864\n",
      "Epoch: 21 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.723 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.0002992528439203236\n",
      "Epoch: 22 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.720 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.0002991800584079171\n",
      "Epoch: 23 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.718 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.0002991039001598393\n",
      "Epoch: 24 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.715 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.00029902437089791324\n",
      "Epoch: 25 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.713 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.00029894147242017524\n",
      "Epoch: 26 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.710 | Train Acc: 0.43%\n",
      "\t scheduled_lr : 0.000298855206600835\n",
      "Epoch: 27 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.707 | Train Acc: 0.46%\n",
      "\t scheduled_lr : 0.00029876557539023187\n",
      "Epoch: 28 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.705 | Train Acc: 0.46%\n",
      "\t scheduled_lr : 0.00029867258081479214\n",
      "Epoch: 29 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.702 | Train Acc: 0.46%\n",
      "\t scheduled_lr : 0.0002985762249769829\n",
      "Epoch: 30 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.699 | Train Acc: 0.50%\n",
      "\t scheduled_lr : 0.00029847651005526386\n",
      "Epoch: 31 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.695 | Train Acc: 0.50%\n",
      "\t scheduled_lr : 0.000298373438304039\n",
      "Epoch: 32 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.693 | Train Acc: 0.50%\n",
      "\t scheduled_lr : 0.00029826701205360405\n",
      "Epoch: 33 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.690 | Train Acc: 0.50%\n",
      "\t scheduled_lr : 0.00029815723371009626\n",
      "Epoch: 34 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.687 | Train Acc: 0.50%\n",
      "\t scheduled_lr : 0.0002980441057554381\n",
      "Epoch: 35 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.685 | Train Acc: 0.50%\n",
      "\t scheduled_lr : 0.0002979276307472815\n",
      "Epoch: 36 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.683 | Train Acc: 0.50%\n",
      "\t scheduled_lr : 0.00029780781131895053\n",
      "Epoch: 37 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.681 | Train Acc: 0.50%\n",
      "\t scheduled_lr : 0.0002976846501793811\n",
      "Epoch: 38 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.679 | Train Acc: 0.50%\n",
      "\t scheduled_lr : 0.0002975581501130608\n",
      "Epoch: 39 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.677 | Train Acc: 0.50%\n",
      "\t scheduled_lr : 0.00029742831397996467\n",
      "Epoch: 40 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.676 | Train Acc: 0.50%\n",
      "\t scheduled_lr : 0.00029729514471549164\n",
      "Epoch: 41 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.674 | Train Acc: 0.50%\n",
      "\t scheduled_lr : 0.00029715864533039725\n",
      "Epoch: 42 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.673 | Train Acc: 0.50%\n",
      "\t scheduled_lr : 0.0002970188189107266\n",
      "Epoch: 43 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.671 | Train Acc: 0.50%\n",
      "\t scheduled_lr : 0.0002968756686177439\n",
      "Epoch: 44 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.670 | Train Acc: 0.50%\n",
      "\t scheduled_lr : 0.0002967291976878605\n",
      "Epoch: 45 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.669 | Train Acc: 0.50%\n",
      "\t scheduled_lr : 0.00029657940943256315\n",
      "Epoch: 46 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.649 | Train Acc: 0.57%\n",
      "\t scheduled_lr : 0.00029642630723833766\n",
      "Epoch: 47 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.605 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.0002962698945665932\n",
      "Epoch: 48 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.605 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.00029611017495358415\n",
      "Epoch: 49 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.603 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002959471520103295\n",
      "Epoch: 50 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.602 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00029578082942253146\n",
      "Epoch: 51 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.601 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002956112109504926\n",
      "Epoch: 52 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.599 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00029543830042903015\n",
      "Epoch: 53 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.598 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00029526210176738973\n",
      "Epoch: 54 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.597 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002950826189491568\n",
      "Epoch: 55 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.596 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002948998560321666\n",
      "Epoch: 56 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.595 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00029471381714841273\n",
      "Epoch: 57 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.594 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00029452450650395277\n",
      "Epoch: 58 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.593 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00029433192837881447\n",
      "Epoch: 59 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.592 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.000294136087126898\n",
      "Epoch: 60 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.591 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00029393698717587854\n",
      "Epoch: 61 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.590 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.00029373463302710483\n",
      "Epoch: 62 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.589 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.00029352902925549836\n",
      "Epoch: 63 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.588 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.00029332018050944974\n",
      "Epoch: 64 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.587 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.0002931080915107135\n",
      "Epoch: 65 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.586 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.00029289276705430126\n",
      "Epoch: 66 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.585 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.0002926742120083738\n",
      "Epoch: 67 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.584 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.00029245243131413026\n",
      "Epoch: 68 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.584 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.0002922274299856969\n",
      "Epoch: 69 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.583 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.00029199921311001383\n",
      "Epoch: 70 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.582 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00029176778584671996\n",
      "Epoch: 71 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.581 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00029153315342803554\n",
      "Epoch: 72 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.580 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.000291295321158645\n",
      "Epoch: 73 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.580 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002910542944155768\n",
      "Epoch: 74 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.579 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002908100786480813\n",
      "Epoch: 75 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.578 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00029056267937750766\n",
      "Epoch: 76 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.578 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002903121021971798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.577 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002900583527722688\n",
      "Epoch: 78 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.576 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002898014368396658\n",
      "Epoch: 79 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.576 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.000289541360207852\n",
      "Epoch: 80 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.575 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00028927812875676677\n",
      "Epoch: 81 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.575 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00028901174843767543\n",
      "Epoch: 82 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.574 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00028874222527303453\n",
      "Epoch: 83 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.574 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002884695653563554\n",
      "Epoch: 84 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.573 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00028819377485206663\n",
      "Epoch: 85 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.572 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.0002879148599953747\n",
      "Epoch: 86 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.572 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.00028763282709212343\n",
      "Epoch: 87 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.571 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.00028734768251864997\n",
      "Epoch: 88 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.571 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002870594327216425\n",
      "Epoch: 89 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.570 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002867680842179936\n",
      "Epoch: 90 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.570 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002864736435946521\n",
      "Epoch: 91 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.569 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00028617611750847573\n",
      "Epoch: 92 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.569 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002858755126860796\n",
      "Epoch: 93 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.568 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002855718359236846\n",
      "Epoch: 94 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.568 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002852650940869632\n",
      "Epoch: 95 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.567 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00028495529411088483\n",
      "Epoch: 96 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.567 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00028464244299955895\n",
      "Epoch: 97 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.567 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00028432654782607606\n",
      "Epoch: 98 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.566 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002840076157323488\n",
      "Epoch: 99 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.566 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00028368565392894994\n",
      "Epoch: 100 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.565 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002833606696949492\n",
      "Epoch: 101 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.565 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00028303267037774877\n",
      "Epoch: 102 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.564 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00028270166339291775\n",
      "Epoch: 103 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.564 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00028236765622402396\n",
      "Epoch: 104 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.564 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002820306564224642\n",
      "Epoch: 105 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.563 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002816906716072953\n",
      "Epoch: 106 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.563 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002813477094650597\n",
      "Epoch: 107 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.562 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00028100177774961337\n",
      "Epoch: 108 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.562 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00028065288428194947\n",
      "Epoch: 109 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.561 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002803010369500221\n",
      "Epoch: 110 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.561 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002799462437085678\n",
      "Epoch: 111 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.561 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002795885125789256\n",
      "Epoch: 112 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.560 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00027922785164885533\n",
      "Epoch: 113 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.560 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002788642690723559\n",
      "Epoch: 114 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.560 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002784977730694799\n",
      "Epoch: 115 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.559 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002781283719261478\n",
      "Epoch: 116 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.559 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00027775607399396134\n",
      "Epoch: 117 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.558 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00027738088769001435\n",
      "Epoch: 118 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.558 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.000277002821496702\n",
      "Epoch: 119 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.557 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00027662188396152947\n",
      "Epoch: 120 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.557 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002762380836969189\n",
      "Epoch: 121 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.556 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002758514293800144\n",
      "Epoch: 122 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.556 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00027546192975248535\n",
      "Epoch: 123 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.556 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00027506959362032994\n",
      "Epoch: 124 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.555 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.000274674429853675\n",
      "Epoch: 125 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.555 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002742764473865763\n",
      "Epoch: 126 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.554 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002738756552168159\n",
      "Epoch: 127 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.554 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00027347206240569896\n",
      "Epoch: 128 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.553 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00027306567807784915\n",
      "Epoch: 129 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.552 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00027265651142100193\n",
      "Epoch: 130 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.552 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00027224457168579705\n",
      "Epoch: 131 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.552 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002718298681855694\n",
      "Epoch: 132 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.551 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00027141241029613844\n",
      "Epoch: 133 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.550 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.000270992207455596\n",
      "Epoch: 134 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.550 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002705692691640932\n",
      "Epoch: 135 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.550 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002701436049836259\n",
      "Epoch: 136 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.549 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002697152245378177\n",
      "Epoch: 137 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.549 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002692841375117033\n",
      "Epoch: 138 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.548 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002688503536515089\n",
      "Epoch: 139 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.548 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002684138827644318\n",
      "Epoch: 140 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.547 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00026797473471841933\n",
      "Epoch: 141 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.546 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00026753291944194506\n",
      "Epoch: 142 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.546 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00026708844692378445\n",
      "Epoch: 143 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.546 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00026664132721278993\n",
      "Epoch: 144 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.545 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002661915704176621\n",
      "Epoch: 145 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.545 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002657391867067227\n",
      "Epoch: 146 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.545 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002652841863076833\n",
      "Epoch: 147 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.543 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002648265795074157\n",
      "Epoch: 148 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.543 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002643663766517179\n",
      "Epoch: 149 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.542 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002639035881450811\n",
      "Epoch: 150 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.542 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002634382244504537\n",
      "Epoch: 151 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.541 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00026297029608900586\n",
      "Epoch: 152 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.541 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00026249981363989084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 153 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.540 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.0002620267877400056\n",
      "Epoch: 154 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.538 | Train Acc: 0.68%\n",
      "\t scheduled_lr : 0.00026155122908375094\n",
      "Epoch: 155 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.537 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.00026107314842278926\n",
      "Epoch: 156 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.536 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.00026059255656580167\n",
      "Epoch: 157 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.535 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.0002601094643782441\n",
      "Epoch: 158 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.535 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.0002596238827821007\n",
      "Epoch: 159 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.533 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.00025913582275563746\n",
      "Epoch: 160 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.532 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.0002586452953331541\n",
      "Epoch: 161 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.532 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.00025815231160473425\n",
      "Epoch: 162 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.532 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.0002576568827159949\n",
      "Epoch: 163 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.531 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.0002571590198678346\n",
      "Epoch: 164 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.531 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.00025665873431617996\n",
      "Epoch: 165 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.530 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.0002561560373717312\n",
      "Epoch: 166 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.530 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.0002556509403997067\n",
      "Epoch: 167 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.529 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.00025514345481958536\n",
      "Epoch: 168 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.529 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.0002546335921048495\n",
      "Epoch: 169 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.528 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.0002541213637827245\n",
      "Epoch: 170 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.528 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.0002536067814339183\n",
      "Epoch: 171 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.526 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.00025308985669236057\n",
      "Epoch: 172 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.526 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.0002525706012449382\n",
      "Epoch: 173 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.525 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.0002520490268312324\n",
      "Epoch: 174 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.525 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.0002515251452432522\n",
      "Epoch: 175 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.525 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.00025099896832516885\n",
      "Epoch: 176 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.524 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.000250470507973047\n",
      "Epoch: 177 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.524 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.0002499397761345766\n",
      "Epoch: 178 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.523 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.00024940678480880245\n",
      "Epoch: 179 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.523 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.0002488715460458531\n",
      "Epoch: 180 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.522 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.000248334071946668\n",
      "Epoch: 181 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.522 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.0002477943746627244\n",
      "Epoch: 182 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.521 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.0002472524663957621\n",
      "Epoch: 183 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.520 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.000246708359397508\n",
      "Epoch: 184 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.521 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.00024616206596939923\n",
      "Epoch: 185 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.519 | Train Acc: 0.71%\n",
      "\t scheduled_lr : 0.00024561359846230434\n",
      "Epoch: 186 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.519 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00024506296927624503\n",
      "Epoch: 187 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.518 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00024451019086011507\n",
      "Epoch: 188 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.518 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00024395527571139877\n",
      "Epoch: 189 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.517 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.0002433982363758895\n",
      "Epoch: 190 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.517 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00024283908544740445\n",
      "Epoch: 191 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.516 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00024227783556750123\n",
      "Epoch: 192 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.516 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00024171449942519136\n",
      "Epoch: 193 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.515 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.0002411490897566537\n",
      "Epoch: 194 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.515 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00024058161934494652\n",
      "Epoch: 195 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.514 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00024001210101971785\n",
      "Epoch: 196 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.513 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00023944054765691672\n",
      "Epoch: 197 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.512 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.0002388669721785007\n",
      "Epoch: 198 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.512 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00023829138755214477\n",
      "Epoch: 199 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.511 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00023771380679094717\n",
      "Epoch: 200 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.511 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00023713424295313624\n",
      "Epoch: 201 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.510 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00023655270914177434\n",
      "Epoch: 202 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.510 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00023596921850446213\n",
      "Epoch: 203 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.509 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00023538378423304117\n",
      "Epoch: 204 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.509 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00023479641956329552\n",
      "Epoch: 205 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.508 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00023420713777465277\n",
      "Epoch: 206 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.508 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00023361595218988367\n",
      "Epoch: 207 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.507 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.0002330228761748007\n",
      "Epoch: 208 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.506 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.0002324279231379565\n",
      "Epoch: 209 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.506 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.0002318311065303398\n",
      "Epoch: 210 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.504 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00023123243984507236\n",
      "Epoch: 211 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.504 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00023063193661710323\n",
      "Epoch: 212 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.503 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.0002300296104229027\n",
      "Epoch: 213 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.503 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00022942547488015598\n",
      "Epoch: 214 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.502 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00022881954364745443\n",
      "Epoch: 215 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.501 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.0002282118304239877\n",
      "Epoch: 216 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.501 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00022760234894923329\n",
      "Epoch: 217 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.501 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00022699111300264618\n",
      "Epoch: 218 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.499 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00022637813640334742\n",
      "Epoch: 219 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.499 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00022576343300981176\n",
      "Epoch: 220 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.498 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00022514701671955378\n",
      "Epoch: 221 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.498 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.0002245289014688142\n",
      "Epoch: 222 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.497 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.0002239091012322447\n",
      "Epoch: 223 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.496 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00022328763002259206\n",
      "Epoch: 224 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.495 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.0002226645018903812\n",
      "Epoch: 225 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.494 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00022203973092359714\n",
      "Epoch: 226 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.494 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.0002214133312473676\n",
      "Epoch: 227 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.493 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00022078531702364248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 228 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.492 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00022015570245087433\n",
      "Epoch: 229 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.492 | Train Acc: 0.75%\n",
      "\t scheduled_lr : 0.00021952450176369705\n",
      "Epoch: 230 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.491 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00021889172923260418\n",
      "Epoch: 231 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.490 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00021825739916362663\n",
      "Epoch: 232 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.490 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00021762152589800842\n",
      "Epoch: 233 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.489 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00021698412381188328\n",
      "Epoch: 234 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.489 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00021634520731594886\n",
      "Epoch: 235 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.489 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0002157047908551419\n",
      "Epoch: 236 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.488 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00021506288890831043\n",
      "Epoch: 237 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.488 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00021441951598788752\n",
      "Epoch: 238 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.487 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00021377468663956255\n",
      "Epoch: 239 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.486 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00021312841544195263\n",
      "Epoch: 240 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.486 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0002124807170062728\n",
      "Epoch: 241 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.484 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00021183160597600597\n",
      "Epoch: 242 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.485 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0002111810970265715\n",
      "Epoch: 243 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.483 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00021052920486499372\n",
      "Epoch: 244 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.483 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0002098759442295691\n",
      "Epoch: 245 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.482 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00020922132988953346\n",
      "Epoch: 246 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.482 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00020856537664472763\n",
      "Epoch: 247 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.480 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00020790809932526319\n",
      "Epoch: 248 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.480 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0002072495127911871\n",
      "Epoch: 249 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.479 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00020658963193214547\n",
      "Epoch: 250 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.479 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00020592847166704743\n",
      "Epoch: 251 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.478 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00020526604694372726\n",
      "Epoch: 252 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.478 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0002046023727386069\n",
      "Epoch: 253 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.477 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0002039374640563572\n",
      "Epoch: 254 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.476 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00020327133592955854\n",
      "Epoch: 255 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.476 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00020260400341836132\n",
      "Epoch: 256 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.475 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00020193548161014498\n",
      "Epoch: 257 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.474 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00020126578561917733\n",
      "Epoch: 258 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.474 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00020059493058627258\n",
      "Epoch: 259 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.474 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00019992293167844923\n",
      "Epoch: 260 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.473 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.000199249804088587\n",
      "Epoch: 261 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.472 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00019857556303508355\n",
      "Epoch: 262 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.473 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00019790022376150998\n",
      "Epoch: 263 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.472 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0001972238015362668\n",
      "Epoch: 264 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.472 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00019654631165223817\n",
      "Epoch: 265 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.470 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00019586776942644656\n",
      "Epoch: 266 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.471 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0001951881901997061\n",
      "Epoch: 267 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.471 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0001945075893362763\n",
      "Epoch: 268 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.470 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00019382598222351404\n",
      "Epoch: 269 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.469 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00019314338427152598\n",
      "Epoch: 270 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.468 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0001924598109128204\n",
      "Epoch: 271 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.468 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0001917752776019578\n",
      "Epoch: 272 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.468 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00019108979981520156\n",
      "Epoch: 273 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.466 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00019040339305016892\n",
      "Epoch: 274 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.467 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00018971607282547938\n",
      "Epoch: 275 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.465 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0001890278546804044\n",
      "Epoch: 276 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.465 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0001883387541745162\n",
      "Epoch: 277 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.465 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00018764878688733587\n",
      "Epoch: 278 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.465 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.000186957968417981\n",
      "Epoch: 279 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.463 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00018626631438481322\n",
      "Epoch: 280 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.464 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.000185573840425085\n",
      "Epoch: 281 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.461 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00018488056219458603\n",
      "Epoch: 282 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.464 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00018418649536728932\n",
      "Epoch: 283 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.460 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0001834916556349971\n",
      "Epoch: 284 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.462 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00018279605870698525\n",
      "Epoch: 285 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.459 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00018209972030964943\n",
      "Epoch: 286 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.464 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00018140265618614833\n",
      "Epoch: 287 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.458 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0001807048820960484\n",
      "Epoch: 288 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.458 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00018000641381496718\n",
      "Epoch: 289 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.458 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00017930726713421711\n",
      "Epoch: 290 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.460 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00017860745786044783\n",
      "Epoch: 291 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.458 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00017790700181528963\n",
      "Epoch: 292 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.459 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00017720591483499497\n",
      "Epoch: 293 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.454 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00017650421277008103\n",
      "Epoch: 294 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.461 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.000175801911484971\n",
      "Epoch: 295 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.453 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00017509902685763573\n",
      "Epoch: 296 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.456 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00017439557477923429\n",
      "Epoch: 297 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.455 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00017369157115375506\n",
      "Epoch: 298 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.454 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0001729870318976561\n",
      "Epoch: 299 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.453 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00017228197293950526\n",
      "Epoch: 300 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.453 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0001715764102196201\n",
      "Epoch: 301 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.455 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0001708703596897072\n",
      "Epoch: 302 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.450 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00017016383731250232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 303 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.455 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00016945685906140856\n",
      "Epoch: 304 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.449 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0001687494409201358\n",
      "Epoch: 305 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.452 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0001680415988823391\n",
      "Epoch: 306 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.448 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00016733334895125716\n",
      "Epoch: 307 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.449 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0001666247071393505\n",
      "Epoch: 308 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.452 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00016591568946793962\n",
      "Epoch: 309 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.446 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00016520631196684268\n",
      "Epoch: 310 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.450 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0001644965906740127\n",
      "Epoch: 311 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.447 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00016378654163517564\n",
      "Epoch: 312 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.445 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0001630761809034673\n",
      "Epoch: 313 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.447 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0001623655245390702\n",
      "Epoch: 314 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.446 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00016165458860885066\n",
      "Epoch: 315 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.445 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.0001609433891859958\n",
      "Epoch: 316 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.447 | Train Acc: 0.79%\n",
      "\t scheduled_lr : 0.00016023194234964977\n",
      "Epoch: 317 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.446 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.0001595202641845502\n",
      "Epoch: 318 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.444 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.0001588083707806652\n",
      "Epoch: 319 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.445 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00015809627823282847\n",
      "Epoch: 320 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.442 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00015738400264037644\n",
      "Epoch: 321 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.445 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00015667156010678378\n",
      "Epoch: 322 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.440 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00015595896673929968\n",
      "Epoch: 323 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.444 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00015524623864858304\n",
      "Epoch: 324 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.440 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00015453339194833896\n",
      "Epoch: 325 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.441 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.0001538204427549541\n",
      "Epoch: 326 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.440 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00015310740718713225\n",
      "Epoch: 327 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.440 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.0001523943013655299\n",
      "Epoch: 328 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.441 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00015168114141239208\n",
      "Epoch: 329 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.440 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00015096794345118757\n",
      "Epoch: 330 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.440 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00015025472360624445\n",
      "Epoch: 331 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.435 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.0001495414980023857\n",
      "Epoch: 332 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.441 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.0001488282827645641\n",
      "Epoch: 333 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.436 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00014811509401749836\n",
      "Epoch: 334 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.436 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.0001474019478853083\n",
      "Epoch: 335 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.436 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.0001466888604911504\n",
      "Epoch: 336 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.436 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00014597584795685267\n",
      "Epoch: 337 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.434 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00014526292640255117\n",
      "Epoch: 338 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.437 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00014455011194632476\n",
      "Epoch: 339 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.434 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.000143837420703831\n",
      "Epoch: 340 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.433 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00014312486878794193\n",
      "Epoch: 341 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.434 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00014241247230837946\n",
      "Epoch: 342 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.432 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00014170024737135143\n",
      "Epoch: 343 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.430 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.0001409882100791872\n",
      "Epoch: 344 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.432 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.000140276376529974\n",
      "Epoch: 345 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.431 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.0001395647628171926\n",
      "Epoch: 346 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.433 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00013885338502935357\n",
      "Epoch: 347 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.430 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.0001381422592496336\n",
      "Epoch: 348 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.430 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.0001374314015555118\n",
      "Epoch: 349 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.430 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.0001367208280184065\n",
      "Epoch: 350 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.429 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00013601055470331138\n",
      "Epoch: 351 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.428 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00013530059766843298\n",
      "Epoch: 352 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.427 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.0001345909729648266\n",
      "Epoch: 353 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.426 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.0001338816966360345\n",
      "Epoch: 354 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.426 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00013317278471772247\n",
      "Epoch: 355 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.426 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00013246425323731783\n",
      "Epoch: 356 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.423 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00013175611821364644\n",
      "Epoch: 357 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.422 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00013104839565657097\n",
      "Epoch: 358 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.419 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.000130341101566629\n",
      "Epoch: 359 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.415 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.000129634251934671\n",
      "Epoch: 360 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.413 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00012892786274149875\n",
      "Epoch: 361 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.412 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.0001282219499575045\n",
      "Epoch: 362 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.412 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00012751652954230951\n",
      "Epoch: 363 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.411 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00012681161744440325\n",
      "Epoch: 364 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.411 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00012610722960078297\n",
      "Epoch: 365 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.410 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.0001254033819365933\n",
      "Epoch: 366 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.409 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00012470009036476626\n",
      "Epoch: 367 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.409 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00012399737078566138\n",
      "Epoch: 368 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.409 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00012329523908670632\n",
      "Epoch: 369 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.408 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00012259371114203775\n",
      "Epoch: 370 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.408 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00012189280281214241\n",
      "Epoch: 371 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.408 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.0001211925299434982\n",
      "Epoch: 372 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.408 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00012049290836821646\n",
      "Epoch: 373 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.407 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00011979395390368375\n",
      "Epoch: 374 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.407 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00011909568235220424\n",
      "Epoch: 375 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.407 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00011839810950064225\n",
      "Epoch: 376 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.407 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00011770125112006579\n",
      "Epoch: 377 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.407 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00011700512296538986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 378 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.406 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00011630974077502\n",
      "Epoch: 379 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.406 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00011561512027049641\n",
      "Epoch: 380 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.406 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.0001149212771561392\n",
      "Epoch: 381 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.405 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00011422822711869243\n",
      "Epoch: 382 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.405 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00011353598582697031\n",
      "Epoch: 383 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.405 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00011284456893150199\n",
      "Epoch: 384 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.405 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00011215399206417877\n",
      "Epoch: 385 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.405 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00011146427083789996\n",
      "Epoch: 386 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.404 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00011077542084622005\n",
      "Epoch: 387 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.404 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00011008745766299639\n",
      "Epoch: 388 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.404 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00010940039684203679\n",
      "Epoch: 389 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.404 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00010871425391674821\n",
      "Epoch: 390 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.404 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00010802904439978514\n",
      "Epoch: 391 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.403 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00010734478378269927\n",
      "Epoch: 392 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.403 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00010666148753558905\n",
      "Epoch: 393 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.403 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00010597917110675008\n",
      "Epoch: 394 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.403 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.0001052978499223255\n",
      "Epoch: 395 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.402 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00010461753938595778\n",
      "Epoch: 396 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.402 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00010393825487843996\n",
      "Epoch: 397 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.402 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00010326001175736816\n",
      "Epoch: 398 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.402 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00010258282535679441\n",
      "Epoch: 399 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.402 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00010190671098687972\n",
      "Epoch: 400 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.402 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00010123168393354842\n",
      "Epoch: 401 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.401 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 0.00010055775945814175\n",
      "Epoch: 402 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.401 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 9.988495279707383e-05\n",
      "Epoch: 403 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.401 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 9.921327916148646e-05\n",
      "Epoch: 404 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.401 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 9.854275373690552e-05\n",
      "Epoch: 405 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.401 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 9.787339168289733e-05\n",
      "Epoch: 406 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.400 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 9.720520813272652e-05\n",
      "Epoch: 407 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.400 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 9.653821819301323e-05\n",
      "Epoch: 408 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.400 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 9.58724369433922e-05\n",
      "Epoch: 409 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.400 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 9.520787943617117e-05\n",
      "Epoch: 410 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.400 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 9.454456069599103e-05\n",
      "Epoch: 411 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.399 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 9.388249571948622e-05\n",
      "Epoch: 412 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.399 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 9.322169947494514e-05\n",
      "Epoch: 413 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.399 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 9.256218690197235e-05\n",
      "Epoch: 414 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.399 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 9.190397291115032e-05\n",
      "Epoch: 415 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.399 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 9.124707238370275e-05\n",
      "Epoch: 416 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.399 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 9.059150017115777e-05\n",
      "Epoch: 417 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.399 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 8.993727109501237e-05\n",
      "Epoch: 418 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.398 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 8.928439994639727e-05\n",
      "Epoch: 419 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.398 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 8.863290148574251e-05\n",
      "Epoch: 420 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.398 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 8.798279044244368e-05\n",
      "Epoch: 421 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.398 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 8.733408151452901e-05\n",
      "Epoch: 422 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.398 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 8.668678936832695e-05\n",
      "Epoch: 423 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.397 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 8.604092863813463e-05\n",
      "Epoch: 424 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.397 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 8.539651392588719e-05\n",
      "Epoch: 425 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.397 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 8.475355980082743e-05\n",
      "Epoch: 426 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.397 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 8.411208079917647e-05\n",
      "Epoch: 427 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.397 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 8.347209142380499e-05\n",
      "Epoch: 428 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.397 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 8.28336061439056e-05\n",
      "Epoch: 429 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.396 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 8.219663939466562e-05\n",
      "Epoch: 430 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.396 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 8.156120557694067e-05\n",
      "Epoch: 431 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.396 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 8.092731905692887e-05\n",
      "Epoch: 432 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.396 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 8.029499416584665e-05\n",
      "Epoch: 433 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.396 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 7.966424519960413e-05\n",
      "Epoch: 434 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.396 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 7.903508641848229e-05\n",
      "Epoch: 435 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.395 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 7.840753204681018e-05\n",
      "Epoch: 436 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.395 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 7.778159627264387e-05\n",
      "Epoch: 437 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.395 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 7.715729324744524e-05\n",
      "Epoch: 438 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.395 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 7.653463708576219e-05\n",
      "Epoch: 439 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.395 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 7.591364186490961e-05\n",
      "Epoch: 440 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.395 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 7.529432162465084e-05\n",
      "Epoch: 441 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.395 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 7.467669036688066e-05\n",
      "Epoch: 442 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.395 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 7.406076205530835e-05\n",
      "Epoch: 443 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.394 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 7.344655061514232e-05\n",
      "Epoch: 444 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.394 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 7.283406993277494e-05\n",
      "Epoch: 445 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.394 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 7.222333385546869e-05\n",
      "Epoch: 446 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.394 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 7.161435619104345e-05\n",
      "Epoch: 447 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.394 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 7.100715070756388e-05\n",
      "Epoch: 448 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.394 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 7.04017311330283e-05\n",
      "Epoch: 449 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.393 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 6.979811115505819e-05\n",
      "Epoch: 450 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.393 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 6.919630442058923e-05\n",
      "Epoch: 451 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.393 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 6.859632453556217e-05\n",
      "Epoch: 452 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.393 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 6.799818506461552e-05\n",
      "Epoch: 453 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.393 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 6.740189953077864e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 454 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.393 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 6.680748141516636e-05\n",
      "Epoch: 455 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.393 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 6.621494415667404e-05\n",
      "Epoch: 456 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.393 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 6.562430115167346e-05\n",
      "Epoch: 457 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.392 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 6.503556575371055e-05\n",
      "Epoch: 458 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.392 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 6.444875127320276e-05\n",
      "Epoch: 459 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.392 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 6.386387097713873e-05\n",
      "Epoch: 460 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.392 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 6.328093808877806e-05\n",
      "Epoch: 461 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.392 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 6.269996578735243e-05\n",
      "Epoch: 462 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.392 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 6.21209672077675e-05\n",
      "Epoch: 463 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.392 | Train Acc: 0.82%\n",
      "\t scheduled_lr : 6.154395544030614e-05\n",
      "Epoch: 464 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.391 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 6.096894353033242e-05\n",
      "Epoch: 465 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.391 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 6.039594447799666e-05\n",
      "Epoch: 466 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.391 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 5.982497123794147e-05\n",
      "Epoch: 467 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.391 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 5.925603671900886e-05\n",
      "Epoch: 468 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.391 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 5.868915378394859e-05\n",
      "Epoch: 469 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.391 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 5.8124335249127044e-05\n",
      "Epoch: 470 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.391 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 5.756159388423782e-05\n",
      "Epoch: 471 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.391 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 5.7000942412012573e-05\n",
      "Epoch: 472 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.391 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 5.644239350793388e-05\n",
      "Epoch: 473 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.390 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 5.5885959799948325e-05\n",
      "Epoch: 474 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.390 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 5.5331653868181234e-05\n",
      "Epoch: 475 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.390 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 5.477948824465193e-05\n",
      "Epoch: 476 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.390 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 5.422947541299065e-05\n",
      "Epoch: 477 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.390 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 5.3681627808156397e-05\n",
      "Epoch: 478 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.390 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 5.31359578161556e-05\n",
      "Epoch: 479 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.390 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 5.259247777376206e-05\n",
      "Epoch: 480 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.390 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 5.205119996823819e-05\n",
      "Epoch: 481 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.390 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 5.1512136637057264e-05\n",
      "Epoch: 482 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.389 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 5.0975299967626367e-05\n",
      "Epoch: 483 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.389 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 5.0440702097011495e-05\n",
      "Epoch: 484 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.389 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 4.9908355111662424e-05\n",
      "Epoch: 485 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.389 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 4.937827104714004e-05\n",
      "Epoch: 486 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.389 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 4.885046188784394e-05\n",
      "Epoch: 487 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.389 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 4.8324939566741555e-05\n",
      "Epoch: 488 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.389 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 4.780171596509843e-05\n",
      "Epoch: 489 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.389 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 4.7280802912209404e-05\n",
      "Epoch: 490 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.389 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 4.676221218513138e-05\n",
      "Epoch: 491 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.389 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 4.6245955508417e-05\n",
      "Epoch: 492 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.389 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 4.573204455384958e-05\n",
      "Epoch: 493 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.388 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 4.522049094017897e-05\n",
      "Epoch: 494 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.388 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 4.471130623285941e-05\n",
      "Epoch: 495 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.388 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 4.420450194378761e-05\n",
      "Epoch: 496 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.388 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 4.370008953104268e-05\n",
      "Epoch: 497 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.388 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 4.3198080398626954e-05\n",
      "Epoch: 498 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.388 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 4.269848589620819e-05\n",
      "Epoch: 499 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.388 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 4.220131731886308e-05\n",
      "Epoch: 500 | Epoch Time: 0m 0s\n",
      "\t Train Loss: 0.388 | Train Acc: 0.86%\n",
      "\t scheduled_lr : 4.170658590682189e-05\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, args.epochs):\n",
    "    \"\"\"\n",
    "    # start timer\n",
    "    start_time = time.time() # 확인용 코드\n",
    "    \"\"\"\n",
    "    # 모델 학습 소요시간\n",
    "    start_time = time.monotonic()\n",
    "    \n",
    "    # train one epoch + evaluate one epoch\n",
    "    train_summary = train(train_rpt_all_dataset.items(), args.learn_type, args.input_size, model, optimizer, scheduler, loss_fn, metric_fn, args.device)\n",
    "\n",
    "    # write log\n",
    "    train_logger.add_scalar('Loss', train_summary['loss'], epoch + 1)\n",
    "    if(args.learn_type == \"regression\"):\n",
    "        pass\n",
    "    else:\n",
    "        train_logger.add_scalar('Accuracy', train_summary['metric'], epoch + 1)\n",
    "    \n",
    "    # save model\n",
    "    save_checkpoint(args.checkpoints, args.title, model, optimizer, epoch + 1)\n",
    "        \n",
    "    # 모델 학습 소요시간\n",
    "    end_time = time.monotonic()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    # Print log\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    if(args.learn_type == \"regression\"):\n",
    "        print(f'\\t Train Loss: {train_summary[\"loss\"]:.3f}')\n",
    "    else:\n",
    "        print(f'\\t Train Loss: {train_summary[\"loss\"]:.3f} | Train Acc: {train_summary[\"metric\"]:.2f}%')\n",
    "    print(f'\\t scheduled_lr : {scheduler.get_last_lr()[0]}')\n",
    "\n",
    "# 모델 저장\n",
    "torch.save(model.state_dict(), f\"{args.title}.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744bc792",
   "metadata": {},
   "source": [
    "## 6. Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d67fd11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Test Loss: 0.624 | Test Acc: 0.78%\n"
     ]
    }
   ],
   "source": [
    "# 학습된 모델 불러오기\n",
    "model.load_state_dict(torch.load(f\"{args.title}.ckpt\"))\n",
    "\n",
    "# 모델 성능 측정\n",
    "test_summary = evaluate(test_rpt_all_dataset.items(), args.learn_type, args.input_size, model, loss_fn, metric_fn, args.device)\n",
    "\n",
    "# write log\n",
    "test_logger.add_scalar('Loss', test_summary['loss'], epoch + 1)\n",
    "if(args.learn_type == \"regression\"):\n",
    "    pass\n",
    "else:\n",
    "    test_logger.add_scalar('Accuracy', test_summary['metric'], epoch + 1)\n",
    "\n",
    "if(args.learn_type == \"regression\"):\n",
    "    print(f'\\t Test Loss: {test_summary[\"loss\"]:.3f}')\n",
    "else:\n",
    "    print(f'\\t Test Loss: {test_summary[\"loss\"]:.3f} | Test Acc: {test_summary[\"metric\"]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4224cc69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BangEnv",
   "language": "python",
   "name": "bangenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
